---
title: "Machine Learning Project"
author: "Roger Oglesby"
date: "Saturday , March 21, 2015"
output: html_document
---
### Introduction
This project will investigate how well a group of enthusiasts perform barbell lifts.
Using data from personal activity trackers, a machine learning model will predict how well 
the activity was performed. Data from control activities will be used to train the model which
will them be used to predict activity from 20 test results.

Data for this experiment comes from http://groupware.les.inf.puc-rio.br/har and thank you to
them for allowing this data to be used.
```{r}
#  Load the packages necessary for the analysis
library(lattice); library(ggplot2); library(caret); library(randomForest)
#  and read in the data to be analysed
testpml <- read.table("./pml-testing.csv",sep=",", as.is=T, header=T)
trainingpml <- read.table("./pml-training.csv", sep="," , as.is=T, header=T)
```
The training data (trainingpml) will be used to build and test a model to predict the outcome from
the test data (testpml).
To allow cross validation and probability testing of the model, the training data will first 
be sub-divided into training and validation subsets.   
    
Due to size and power of my PC, 
a smaller than usual proportion of data will be used for training data allowing more 
data to be used in the validation step. 
This might hinder the final model, but it will mean the code to build the model 
will run in a reasonable time scale on my not highest spec machine.   
Only 40% of data will be used for training, 60% for validation.   
  
### Data Cleaning   
```{r}
#  Set the seed so the that the approach is reproducible
set.seed <- 1234
#  Subset the full training data frame into a smaller training set 
#  with the rest in a validation set
trainIndex <- createDataPartition(trainingpml$classe,p=0.4,list=FALSE)
#  40% of data will be written to training set trainpml 
#  and 60% to validation set validpml
trainpml <- trainingpml[trainIndex,]
validpml <- trainingpml[-trainIndex,]
```
Before modelling, the data will be cleaned.
Data that will not contribute to the analysis will be removed - firstly names and timestamps.
```{r}
#  Remove data not to be used from training and validation data frame
#  - names and timestamps.
trainpml <- trainpml[, -c(1,3,4,5,6,7)]
```
From a cursory look at the data, it is obvious that a lot of readings have missing data. 
If any variable has more than 50% missing data, this data will be removed and will not be used in the model.
```{r}
#  Only keep data if more than half of it is not NA
trainmiss <- colSums(is.na(trainpml)) < (nrow(trainpml)/2)
#  Remove data that will not contribute to the model
trainpml <- trainpml[, trainmiss]
#  Remove data if it is nearly constant and not very useful for prediction
trainnzr <- nearZeroVar(trainpml, saveMetrics=TRUE)
trainpml <- trainpml[, which(trainnzr$nzv==FALSE)]
#  Convert the user names and exercise class type into factor variables
trainpml$user_name  <- as.factor(trainpml$user_name)
trainpml$classe  <- as.factor(trainpml$classe)
#  The clean training data will now be used to build the model  
```
### Building the Model
The clean data will be used to build the models using the caret package and a random forest model.
To allow the models to process in a reasonable time, the number of trees has been limited to 50.
Three models will be tested using various numbers of trees. The best model will be decided by
predicting using the validation data set.
```{r}
modelFit1 <- train(trainpml$classe ~., method="rf",
                   data=trainpml, ntree=5, importance=TRUE)
modelFit2 <- train(trainpml$classe ~., method="rf", 
                   data=trainpml, ntree=10, importance=TRUE)
modelFit3 <- train(trainpml$classe ~., method="rf", 
                   data=trainpml, ntree=50, importance=TRUE)
```
The confusion matrix shows that all models are reasonably accurate with prediction, 
with the best model being the 50 tree model.
```{r,echo=FALSE}
#  Generate the confusion matrix to calculate the accuracy of the four models against the validation data
CM1 <- confusionMatrix(validpml$classe, predict(modelFit1, validpml))
CM2 <- confusionMatrix(validpml$classe, predict(modelFit2, validpml))
CM3 <- confusionMatrix(validpml$classe, predict(modelFit3, validpml))
#  Print out the accuracy of the three models
print("Accuracy of Model 1 -  5 trees"); CM1$overall[1]
print("Accuracy of Model 2 - 10 trees"); CM2$overall[1]
print("Accuracy of Model 3 - 50 trees"); CM3$overall[1]
#  What about the sensitivity and specificity of the best model?
print("Model 3 -  50 trees")
CM3$byClass[,c(1,2)]
```
The best 50 tree model gives an accuracy of over 99.1%, outperforming the other models.   
This model will be used for the final prediction of 20 test cases.  
    
The sensitivity and specificity for all five outcomes (A, B, C D and E) are also all better than 98.5%
indicating that the model is likely to correctly predict at least 19 out of 20 test cases    
   
### Predictions   
Although only Model 2 (50 trees) will be used for the final predictions, how
would the different models change the predictions?
```{r,ECHO=FALSE}
testpml$predict1 <- predict(modelFit1, testpml)
testpml$predict2 <- predict(modelFit2, testpml)
testpml$predict3 <- predict(modelFit3, testpml)
#  This gives the predictions as ....
print("Model 1 -  5 trees"); testpml$predict1
print("Model 2 - 10 trees"); testpml$predict2
print("Model 3 - 50 trees"); testpml$predict3
```
The different models agree on all predictions!  
    
### Conclusions   
The predictions from Model 3 with 50 trees will be used for the final assessment submission.    
The submission routine will be used to write the predictions to 20 files.
```{r}
#  The predictions to be submitted are:
print(testpml$predict3)
pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_", i, ".txt")
    write.table(x[i], file=filename, quote=FALSE, 
                row.names=FALSE, col.names=FALSE)
  }
}
pml_write_files(testpml$predict3)
```
Perhaps a more powerful model could be built, but given the constraints of time and speed of my PC, the chosen model is expected to do very well on the prediction exercise.  
  